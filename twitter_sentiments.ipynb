{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the train and test csv files of tweets provided by Zindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (5287, 3) 5287\n",
      "Test Set: (1962, 2) 1962\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('updated_train.csv')\n",
    "print(\"Training Set:\"% train.columns, train.shape, len(train))\n",
    "test = pd.read_csv('updated_test.csv')\n",
    "print(\"Test Set:\"% test.columns, test.shape, len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets  = train['text']\n",
    "\n",
    "def preprocessing(df, text):\n",
    "    '''data preprocessing function'''\n",
    "    # convert to string:\n",
    "    df = df.astype(str)\n",
    "    \n",
    "    # remove punctuation\n",
    "    df[text] = df[text].str.replace(r'[^\\w\\s]', '')\n",
    "\n",
    "    # remove underscores not picked up as punctuation above\n",
    "    df[text] = df[text].str.replace('_', ' ')\n",
    "    df[text] = df[text].str.replace('#', ' ')\n",
    "    df[text] = df[text].str.replace('[^a-zA-Z#]', ' ')\n",
    "    \n",
    "    # remove  numbers\n",
    "    df[text] = df[text].str.replace(r'\\d[,9][^19]', ' ')\n",
    "\n",
    "    # convert to lowercase\n",
    "    df[text] = df[text].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "    \n",
    "    # spell correction\n",
    "    #df['text'] = df['text'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    df[text] = df[text].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
    "    \n",
    "    # tokenize\n",
    "    #tokens = word_tokenize()\n",
    "    #df[text] = df[text].apply(lambda x:  ' '.join([tokens.tokens]x for x in nltk.word_tokenize))\n",
    "\n",
    "    # stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    #df[text] = df[text].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "    df[text] = df[text].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
    "    \n",
    "    # lemmatize (althouh almost similar to stemming)\n",
    "    df[text] = df[text].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2</td>\n",
       "      <td>explain video take look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3</td>\n",
       "      <td>ed davey fast ramadan contest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4</td>\n",
       "      <td>doja cat good miss nicki minaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_8</td>\n",
       "      <td>bori johnson cheeri wound action persona may s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_9</td>\n",
       "      <td>man terribl even reason get sport start back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>test_2932</td>\n",
       "      <td>fageeru meehaa geyga bandah public fund amp gs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>test_2934</td>\n",
       "      <td>dffn diffus pharmaceut announc pre ind submiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>test_2936</td>\n",
       "      <td>want wish muslim member congress happi ramadan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>test_2937</td>\n",
       "      <td>mean believ conspiraci involv g bill gate micr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>test_2940</td>\n",
       "      <td>rajavi call unit nation secur council take imm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1962 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               text\n",
       "0        test_2                            explain video take look\n",
       "1        test_3                      ed davey fast ramadan contest\n",
       "2        test_4                     doja cat good miss nicki minaj\n",
       "3        test_8  bori johnson cheeri wound action persona may s...\n",
       "4        test_9       man terribl even reason get sport start back\n",
       "...         ...                                                ...\n",
       "1957  test_2932  fageeru meehaa geyga bandah public fund amp gs...\n",
       "1958  test_2934  dffn diffus pharmaceut announc pre ind submiss...\n",
       "1959  test_2936     want wish muslim member congress happi ramadan\n",
       "1960  test_2937  mean believ conspiraci involv g bill gate micr...\n",
       "1961  test_2940  rajavi call unit nation secur council take imm...\n",
       "\n",
       "[1962 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = preprocessing(train, 'text')\n",
    "test = preprocessing(test, 'text')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 bitcoin halv cancel due\n",
       "1       mercyofallah good time wrap granular detail ch...\n",
       "2       day digit india murder e learn g onlin busi re...\n",
       "3       india like run remain rna kit essenti test one...\n",
       "4       tough time best way grow learn case teach help...\n",
       "                              ...                        \n",
       "5282    spread novel among asylum seeker add pile alar...\n",
       "5283    hundr jewish patient treat arab practition mig...\n",
       "5284    beat honestli peopl follow sport fan l share t...\n",
       "5285    help u reach peopl donat share ramadan flyer d...\n",
       "5286    interest rate swap deriv price python harbourf...\n",
       "Name: text, Length: 5287, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']\n",
    "# visualize words covid-related and non-covid related top words in the training datasef\n",
    "#covid_related  = ' '.join([text for text in train['text'][train['target'] == 1]])\n",
    "\n",
    "#wordcloud = WordCloud(width=500, height=700, random_state=21, max_font_size=100).generate(covid_related)\n",
    "#plt.imshow(wordcloud, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2746\n",
       "1    2541\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many tweets are classified are covid related and not covid related\n",
    "# from the output we have ~50% labelled as covid-related and not-covid-related\n",
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# bow vectorizer\n",
    "count_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "# bow feature matrix for train \n",
    "train_vectors_bow  = count_vectorizer.fit_transform(train['text'])\n",
    "train_vectors_bow.todense()\n",
    "# bow of feature matrix for test\n",
    "test_vectors_bow = count_vectorizer.transform(test['text'])\n",
    "#test_vectors_bow.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1962, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#tdif vectorizer\n",
    "tdif_vectorizer  = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "# tdif feature matrix for train dataset\n",
    "train_vectors_tdif = tdif_vectorizer.fit_transform(train['text']) \n",
    "# tdif feature matrix for test dataset\n",
    "test_vectors_tdif  = tdif_vectorizer.transform(test['text'])\n",
    "test_vectors_tdif.todense().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting of te datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# bow features from the train\n",
    "x_train_bow, x_valid_bow, y_train_bow, y_valid_bow = train_test_split(train_vectors_bow, train['target'], random_state=2)\n",
    "# tdif features for the train\n",
    "x_train_tdif, x_valid_tdif, y_train_tdif, y_valid_tdif = train_test_split(train_vectors_tdif, train['target'], test_size=0.3, random_state=17)\n",
    "\n",
    "# logistic regression model\n",
    "Log_Reg = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "# fitting the data\n",
    "Log_Reg.fit(x_train_tdif, y_train_tdif)\n",
    "# predict probability\n",
    "predict_bow = Log_Reg.predict(test_vectors_tdif)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output['ID'] = test['ID']\n",
    "output['target'] = predict_bow\n",
    "predict_bow\n",
    "output.to_csv('sample_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes (Bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8849997929010782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humblefool/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the training set\n",
    "#word_vectorizer = CountVectorizer()\n",
    "X_train = count_vectorizer_bow.fit_transform(train['text'])\n",
    "\n",
    "# Vectorize the testing test\n",
    "X_test = count_vectorizer_bow.transform(test['text'])\n",
    "\n",
    "# Our output variable \"target\" which indicates whether a tweet is diaster tweet\n",
    "y_train = train['target']\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "\n",
    "clf = BernoulliNB()\n",
    "scores = cross_val_score(clf, X_train, y_train)\n",
    "print(scores.mean())\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_test = clf.predict(X_test)\n",
    "output = pd.DataFrame()\n",
    "output['ID'] = test['ID']\n",
    "output['target'] = y_test\n",
    "output.to_csv('sample_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humblefool/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "dtc_scores = cross_val_score(dtc, X_train, y_train)\n",
    "dtc_scores.mean()\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "y_test_dtc = dtc.predict(X_test)\n",
    "output = pd.DataFrame()\n",
    "output['ID'] = test[\"ID\"]\n",
    "output['target']  = y_test_dtc\n",
    "output.to_csv('sample_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humblefool/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ridc = RidgeClassifier()\n",
    "rc_scores = cross_val_score(ridc, X_train, y_train)\n",
    "rc_scores.mean()\n",
    "\n",
    "ridc.fit(X_train, y_train)\n",
    "y_test_ridc = ridc.predict(X_test)\n",
    "output = pd.DataFrame()\n",
    "output['ID']  = test['ID']\n",
    "output['target'] = y_test_ridc\n",
    "output.to_csv('sample_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8971056369751196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humblefool/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/humblefool/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_r = LogisticRegression()\n",
    "log_scores = cross_val_score(log_r, X_train, y_train)\n",
    "print(log_scores.mean())\n",
    "\n",
    "\n",
    "log_r.fit(X_train, y_train)\n",
    "y_test_log =log_r.predict(X_test)\n",
    "output = pd.DataFrame()\n",
    "output['ID'] = test['ID']\n",
    "output['target'] = y_test_log\n",
    "output.to_csv('sample_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('nb', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8986645718774549 \n"
     ]
    }
   ],
   "source": [
    "# split the training data into the training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['text'], train['target'], random_state=0)\n",
    "\n",
    "# fit model\n",
    "model  = pipeline_sgd.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test)\n",
    "# print f1_score, precision score, accuracy score\n",
    "print('F1 Score: {} '.format(f1_score(y_test, y_pred, pos_label='1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test['text'])\n",
    "#np.argmax(test_pred, axis=-1)\n",
    "#test_pred_int = test_pred[:,1] \n",
    "#test_pred_int = test_pred_int.astype(np.int)\n",
    "test['target'] = test_pred\n",
    "submission = test[['ID', 'target']]\n",
    "#submission\n",
    "\n",
    "\n",
    "submission.to_csv('updated_ss.csv', index=False) # writing data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB: 0.8849997929010782 \n",
      " Descision Tree: 0.8583323192997524 \n",
      " Ridge Classifier: 0.8725179516135366 \n",
      " Logistic Regression: 0.8971056369751196 \n",
      " SGDClassifier 0.8986645718774549\n"
     ]
    }
   ],
   "source": [
    "print('BernoulliNB: {} \\n Descision Tree: {} \\n Ridge Classifier: {} \\n Logistic Regression: {} \\n SGDClassifier {}'.format(scores.mean(), \n",
    "                                                                                                                         dtc_scores.mean(),\n",
    "                                                                                                                         rc_scores.mean(),\n",
    "                                                                                                                         log_scores.mean(),\n",
    "                                                                                                                         f1_score(y_test, y_pred, pos_label='1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
